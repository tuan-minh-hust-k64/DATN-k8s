Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:

    kafka.default.svc.cluster.local

Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:

    kafka-broker-0.kafka-broker-headless.default.svc.cluster.local:9092
    kafka-broker-1.kafka-broker-headless.default.svc.cluster.local:9092
    kafka-broker-2.kafka-broker-headless.default.svc.cluster.local:9092

The CLIENT listener for Kafka client connections from within your cluster have been configured with the following security settings: - SASL authentication

To connect a client to your Kafka, you need to create the 'client.properties' configuration files with the content below:

security.protocol=SASL_PLAINTEXT
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
 username="user1" \
 password="$(kubectl get secret kafka-user-passwords --namespace default -o jsonpath='{.data.client-passwords}' | base64 -d | cut -d , -f 1)";

To create a pod that you can use as a Kafka client run the following commands:

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.5.1-debian-11-r41 --namespace default --command -- sleep infinity
    kubectl cp --namespace default /path/to/client.properties kafka-client:/tmp/client.properties
    kubectl exec --tty -i kafka-client --namespace default -- bash

    PRODUCER:
        kafka-console-producer.sh \
            --producer.config /tmp/client.properties \
            --broker-list kafka-broker-0.kafka-broker-headless.default.svc.cluster.local:9092,kafka-broker-1.kafka-broker-headless.default.svc.cluster.local:9092,kafka-broker-2.kafka-broker-headless.default.svc.cluster.local:9092 \
            --topic test

    CONSUMER:

        helm install kafka bitnami/kafka --set zookeeper.enabled=true --set kraft.enabled=false --set controller.replicaCount=0 --set provisioning.replicationFactor=3 --set broker.replicaCount=3 --set  externalZookeeper.servers=zookeeper.default.svc.cluster.local --set listeners.client.protocol=PLAINTEXT --set listeners.external.protocol=PLAINTEXT --set listeners.controller.protocol=PLAINTEXT

---

Schema Registry can be accessed through the following DNS name from within your cluster:

    schema-registry.default.svc.cluster.local (port )

To access Schema Registry from outside the cluster execute the following commands:

1. Get the Schema Registry URL by running these commands:

   export SERVICE_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[0].port}" services schema-registry)
    kubectl port-forward --namespace default svc/schema-registry ${SERVICE_PORT}:${SERVICE_PORT} &
   echo "http://127.0.0.1:${SERVICE_PORT}"

2. Access Schema Registry using the obtained URL.



 postgres-postgresql.default.svc.cluster.local 


 PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:

    postgres-postgresql.default.svc.cluster.local - Read/Write connection

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default postgres-postgresql -o jsonpath="{.data.postgres-password}" | base64 -d)

To connect to your database run the following command:

    kubectl run postgres-postgresql-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql:15.4.0-debian-11-r10 --env="PGPASSWORD=$POSTGRES_PASSWORD" \
      --command -- psql --host postgres-postgresql -U postgres -d postgres -p 5432

    > NOTE: If you access the container using bash, make sure that you execute "/opt/bitnami/scripts/postgresql/entrypoint.sh /bin/bash" in order to avoid the error "psql: local user with ID 1001} does not exist"

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/postgres-postgresql 5432:5432 &
    PGPASSWORD="$POSTGRES_PASSWORD" psql --host 127.0.0.1 -U postgres -d postgres -p 5432

WARNING: The configured password will be ignored on new installation in case when previous PostgreSQL release was deleted through the helm command. In that case, old PVC will have an old password, and setting it through helm won't take effect. Deleting persistent volumes (PVs) will solve the issue.



----------------
helm install postgres postgresql-12.11.1-v2/postgresql/
helm install schema-registry oci://registry-1.docker.io/bitnamicharts/schema-registry
helm install zookeeper oci://registry-1.docker.io/bitnamicharts/zookeeper
helm install kafka bitnami/kafka --set zookeeper.enabled=true --set kraft.enabled=false --set controller.replicaCount=0 --set provisioning.replicationFactor=3  --set broker.replicaCount=3 --set  externalZookeeper.servers=zookeeper.default.svc.cluster.local --set listeners.client.protocol=PLAINTEXT --set listeners.external.protocol=PLAINTEXT --set listeners.controller.protocol=PLAINTEXT

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.1-debian-11-r0 --namespace default --command -- sleep infinity
    kubectl exec --tty -i kafka-client --namespace default -- bash

Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:

    kafka-broker-0.kafka-broker-headless.default.svc.cluster.local:9092
    kafka-broker-1.kafka-broker-headless.default.svc.cluster.local:9092
    kafka-broker-2.kafka-broker-headless.default.svc.cluster.local:9092

To create a pod that you can use as a Kafka client run the following commands:

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.1-debian-11-r0 --namespace default --command -- sleep infinity
    kubectl exec --tty -i kafka-client --namespace default -- bash

    PRODUCER:
        kafka-console-producer.sh \
            --broker-list kafka-broker-0.kafka-broker-headless.default.svc.cluster.local:9092,kafka-broker-1.kafka-broker-headless.default.svc.cluster.local:9092,kafka-1-broker-2.kafka-1-broker-headless.default.svc.cluster.local:9092 \
            --topic test

    CONSUMER:
        kafka-console-consumer.sh --bootstrap-server kafka.default.svc.cluster.local:9092  --topic debezium.order.payment_outbox --from-beginning

            kafka-topics.sh --list --bootstrap-server kafka.default.svc.cluster.local:9092

            kafka-topics.sh --delete --bootstrap-server kafka.default.svc.cluster.local:9092 --topic debezium.order.payment_outbox


            PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:

    post-postgresql.default.svc.cluster.local - Read/Write connection

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default post-postgresql -o jsonpath="{.data.postgres-password}" | base64 -d)

To connect to your database run the following command:

    kubectl run postgres-postgresql-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql:15.4.0-debian-11-r10 --env="PGPASSWORD=$POSTGRES_PASSWORD" \
      --command -- psql --host postgres-postgresql -U postgres -d postgres -p 5432

    > NOTE: If you access the container using bash, make sure that you execute "/opt/bitnami/scripts/postgresql/entrypoint.sh /bin/bash" in order to avoid the error "psql: local user with ID 1001} does not exist"

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/postgres-postgresql 5431:5432 &
    PGPASSWORD="$POSTGRES_PASSWORD" psql --host 127.0.0.1 -U postgres -d postgres -p 5432

WARNING: The configured password will be ignored on new installation in case when previous PostgreSQL release was deleted through the helm command. In that case, old PVC will have an old password, and setting it through helm won't take effect. Deleting persistent volumes (PVs) will solve the issue.